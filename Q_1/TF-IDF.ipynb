{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data_path = \"data/preprocessed_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDF:\n",
    "    def __init__(self, documents, weighting = \"raw\"):\n",
    "        self.documents = documents\n",
    "        self.weighting = weighting\n",
    "\n",
    "        self.N = len(documents)\n",
    "        self.tf = self.compute_tf()\n",
    "        self.idf = self.compute_idf()\n",
    "        self.tf_idf = self.compute_tf_idf()\n",
    "\n",
    "    def compute_tf(self):\n",
    "        tf = {}\n",
    "        for i, document in enumerate(self.documents):\n",
    "            tf[i] = {}\n",
    "            for term in document.split():\n",
    "                if term not in tf[i]:\n",
    "                    tf[i][term] = 0\n",
    "                tf[i][term] += 1\n",
    "        return tf\n",
    "\n",
    "    def compute_idf(self):\n",
    "        idf = {}\n",
    "        for document in self.documents:\n",
    "            for term in document.split():\n",
    "                if term not in idf:\n",
    "                    idf[term] = 0\n",
    "                idf[term] += 1\n",
    "        for term in idf:\n",
    "            idf[term] = np.log(self.N / idf[term])\n",
    "        return idf\n",
    "    \n",
    "    def compute_tf_idf(self):\n",
    "        tf_idf = np.zeros((self.N, len(self.idf)))\n",
    "        for i, document in enumerate(self.documents):\n",
    "            vis = []\n",
    "            for j, term in enumerate(set(document.split())):\n",
    "                term_loc = j\n",
    "                if term in vis:\n",
    "                    term_loc = vis.index(term)\n",
    "                else:\n",
    "                    vis.append(term)\n",
    "                if self.weighting == \"binary\":\n",
    "                    tf_idf[i][term_loc] += self.idf[term]\n",
    "                elif self.weighting == \"raw\":\n",
    "                    tf_idf[i][term_loc] += self.tf[i][term] * self.idf[term]\n",
    "                elif self.weighting == \"term_frequency\":\n",
    "                    tf_idf[i][term_loc] += self.tf[i][term] * self.idf[term] / sum([self.tf[i][t] for t in self.tf[i] if t is not term])\n",
    "                elif self.weighting == \"log_normalization\":\n",
    "                    tf_idf[i][term_loc] += (1 + np.log(self.tf[i][term])) * self.idf[term]\n",
    "                elif self.weighting == \"double_normalization\":\n",
    "                    tf_idf[i][term_loc] += (0.5 + 0.5 * (self.tf[i][term] / max([self.tf[i][t] for t in self.tf[i] if t is not term]))) * self.idf[term]\n",
    "        return tf_idf\n",
    "\n",
    "    def get_tf(self):\n",
    "        return self.tf\n",
    "\n",
    "    def get_idf(self):\n",
    "        return self.idf\n",
    "\n",
    "    def get_tf_idf(self):\n",
    "        return self.tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighting_metrics = [\"binary\", \"raw\", \"term_frequency\", \"log_normalization\", \"double_normalization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for filename in os.listdir(preprocessed_data_path):\n",
    "    with open(preprocessed_data_path + filename, \"r\") as f:\n",
    "        corpus.append(f.read())\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TFIDF(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Jaccard:\n",
    "    def __init__(self, documents, vocab):\n",
    "        self.documents = documents\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def compute_jaccard(self):\n",
    "        jaccard = np.zeros((len(self.documents), len(self.vocab)))\n",
    "        for i, document1 in enumerate(self.documents):\n",
    "            for j, query in enumerate(self.vocab):\n",
    "                jaccard[i][j] = len(set(document1.split()) & set(query.split())) / len(set(document1.split()) | set(query.split()))\n",
    "        return jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard = Jaccard(corpus, tfidf.idf.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jaccard.compute_jaccard(\"investigation\")\n",
    "jaccard_coeff = jaccard.compute_jaccard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
